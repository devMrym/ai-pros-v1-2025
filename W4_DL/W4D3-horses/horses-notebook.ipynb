{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ca2ef2",
   "metadata": {},
   "source": [
    "### installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2004ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision numpy matplotlib Pathlib -qqq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c04f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, Subset, random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1947fe4",
   "metadata": {},
   "source": [
    "### Load Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5640d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'horse-breeds' dataset.\n",
      "Path to dataset files: /kaggle/input/horse-breeds\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olgabelitskaya/horse-breeds\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd125bf",
   "metadata": {},
   "source": [
    "### Split the data into train val, and test set (starified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c903d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to dataset\n",
    "dataset_path = Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "923af36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/kaggle/input/horse-breeds/01_103.png'), PosixPath('/kaggle/input/horse-breeds/03_068.png'), PosixPath('/kaggle/input/horse-breeds/02_060.png'), PosixPath('/kaggle/input/horse-breeds/03_030.png'), PosixPath('/kaggle/input/horse-breeds/07_065.png')]\n",
      "[1, 3, 2, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_paths.append(Path(dataset_path) / file_name)\n",
    "        labels.append(int(file_name[1]))\n",
    "\n",
    "print(image_paths[:5])\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59234952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 536\n",
      "validation samples: 134\n",
      "[2, 3, 2, 5, 5, 2, 1, 2, 5, 7]\n",
      "[7, 2, 2, 6, 6, 1, 1, 5, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "print(f\"training samples: {len(train_paths)}\")\n",
    "print(f\"validation samples: {len(val_paths)}\")\n",
    "print(train_labels[:10])\n",
    "print(val_labels[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a109e7",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceaffac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseBreedDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # ensure 3 channels\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ecb44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8186756",
   "metadata": {},
   "source": [
    "### Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc88867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean values for normalization.\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "# Define the standard deviation values for normalization.\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca795cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # images transforms\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 pixels\n",
    "    transforms.CenterCrop(224),  # Center crop to 224x224 pixels\n",
    "    # bridge to tensor\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    # tensor transforms\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59331a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset instance with the specified image transformations.\n",
    "dataset_transformed = HorseBreedDataset(train_paths, train_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb624730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=.:/env/python\n",
      ".:/env/python\n",
      "/content/ai-pros-v1-2025/W4_DL/C1_M3_Data_Management/C1_M3_Lab_data_management\n",
      "C1_M3_Lab_data_management.ipynb  \u001b[0m\u001b[01;34mcorrupted_flower_data\u001b[0m/  helper_utils.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "NOTEBOOK_NAME = \"C1_M3_Lab_data_management.ipynb\" #TODO: automate this\n",
    "REPO_URL = \"https://github.com/SDAIA-Bootcamps/ai-pros-v1-2025.git\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('in colab')\n",
    "    if os.system('git config --get remote.origin.url') != REPO_URL:\n",
    "        print('cloning...')\n",
    "        !git clone $REPO_URL\n",
    "        repo_dir = REPO_URL.split('/').pop().strip('.git')\n",
    "        print(f'{repo_dir=}')\n",
    "        labdir = next(Path(repo_dir).rglob(NOTEBOOK_NAME)).parent.absolute()\n",
    "        print(f'{labdir=}')\n",
    "        %cd $labdir\n",
    "\n",
    "    # path management for Python\n",
    "    pythonpath, = !echo $PYTHONPATH\n",
    "    if \".\" not in pythonpath.split(\":\"):\n",
    "        pythonpath = \".:\" + pythonpath\n",
    "        %env PYTHONPATH={pythonpath}\n",
    "        !echo $PYTHONPATH\n",
    "\n",
    "# allow \"hot-reloading\" of modules\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# needed for inline plots in some contexts\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "!pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f49c07b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting directory-tree\n",
      "  Downloading directory_tree-1.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Downloading directory_tree-1.0.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: directory-tree\n",
      "Successfully installed directory-tree-1.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install directory-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_utils\n",
    "# Define an index for a sample to retrieve.\n",
    "sel_idx = 10\n",
    "\n",
    "# Retrieve the image and label for the selected index.\n",
    "img, label = dataset_transformed[sel_idx]\n",
    "# Retrieve the transformed image and its label using the same index.\n",
    "img_transformed, label = dataset_transformed[sel_idx]\n",
    "\n",
    "# quick check\n",
    "helper_utils.quick_debug(img_transformed)\n",
    "\n",
    "# Plot the transformed image\n",
    "helper_utils.plot_img(img_transformed, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f13970",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PosixPath' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-437664784.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Retrieve the image and label for the selected index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Retrieve the transformed image and its label using the same index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PosixPath' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import helper_utils\n",
    "# Define an index for a sample to retrieve.\n",
    "sel_idx = 10\n",
    "\n",
    "# Retrieve the image and label for the selected index.\n",
    "img, label = path[sel_idx]\n",
    "# Retrieve the transformed image and its label using the same index.\n",
    "\n",
    "# quick check\n",
    "helper_utils.quick_debug(img_transformed)\n",
    "\n",
    "# Plot the transformed image\n",
    "helper_utils.plot_img(img, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202a15e",
   "metadata": {},
   "source": [
    "### Create Dataloader objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ba2be",
   "metadata": {},
   "source": [
    "#### Display some images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502866c",
   "metadata": {},
   "source": [
    "### Define Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66c574",
   "metadata": {},
   "source": [
    "### define Loss and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86466417",
   "metadata": {},
   "source": [
    "#### Build one_epoch_training function loop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c45b81",
   "metadata": {},
   "source": [
    "### Combine all to train the model\n",
    "it should Save the best model and track train and val loss and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70478df0",
   "metadata": {},
   "source": [
    "### test the model on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33058b",
   "metadata": {},
   "source": [
    "### show some predictions with the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc2f73",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "Is the model overfitting/underfitting?\n",
    "Plot the training and validation loss/accuracy curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b19061",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
